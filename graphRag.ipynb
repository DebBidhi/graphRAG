{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index\n",
    "%pip install llama-index-core \n",
    "%pip install neo4j\n",
    "%pip install llama-index-graph-stores-neo4j\n",
    "%pip install llama_index.embeddings.huggingface\n",
    "%pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locally Running Graph based database via NEO4j using docker\n",
    "``` \n",
    "docker run -p 7474:7474 -p 7687:7687  -v $PWD/data:/data -v $PWD/plugins:/plugins  --name neo4j-apoc  -e NEO4J_apoc_export_file_enabled=true -e NEO4J_apoc_import_file_enabled=true -e NEO4J_apoc_import_file_use__neo4j__config=true -e NEO4J_PLUGINS='[\"apoc\"]' neo4j:latest\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!megablocks not available, using torch.matmul instead\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "#import statment does not matter but needed the pip for >> import einops\n",
    "from tqdm import tqdm \n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"nomic-ai/nomic-embed-text-v1.5\",\n",
    "                                    trust_remote_code=True,\n",
    "                                    cache_folder='./hf_cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"llama3.2:1b\", base_url=\"http://localhost:11434\", request_timeout=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j is connected!\n",
      "Neo4j Graph Store initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "# (running the graph db locally, password exposed not an concern rn!!)\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"neo4j://localhost:7687\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"tango-uncle-flag-loyal-fantasy-7396\")  \n",
    "\n",
    "def test_neo4j_connection():\n",
    "    \"\"\"Test if Neo4j is accessible.\"\"\"\n",
    "    try:\n",
    "        with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "            with driver.session() as session:\n",
    "                result = session.run(\"RETURN 'Neo4j is connected!'\")\n",
    "                print(result.single()[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Neo4j Connection Failed: {e}\")\n",
    "\n",
    "test_neo4j_connection()\n",
    "\n",
    "# Initialize Neo4jPropertyGraphStore\n",
    "try:\n",
    "    graph_store = Neo4jPropertyGraphStore(\n",
    "        username=NEO4J_USERNAME,\n",
    "        password=NEO4J_PASSWORD,\n",
    "        url=NEO4J_URI,\n",
    "    )\n",
    "    print(\"Neo4j Graph Store initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize Neo4j Graph Store: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "loader = SimpleDirectoryReader(\"./dataF/\")\n",
    "\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What I Worked On\n",
       "\n",
       "February 2021\n",
       "\n",
       "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
       "\n",
       "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "# first 500 words\n",
    "display(Markdown(documents[0].text[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import SimpleLLMPathExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934493baed204436b1f4eea02caeda89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|██████████| 22/22 [02:07<00:00,  5.81s/it]\n",
      "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]Embedding attempt failed: The size of tensor a (1002) must match the size of tensor b (993) at non-singleton dimension 1\n",
      "Embedding attempt failed: 'NoneType' object is not subscriptable\n",
      "Embedding attempt failed: The size of tensor a (1015) must match the size of tensor b (1011) at non-singleton dimension 1\n",
      "Embedding attempt failed: The size of tensor a (1007) must match the size of tensor b (993) at non-singleton dimension 1\n",
      "Embedding attempt failed: 'NoneType' object is not subscriptable\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:13<00:00,  4.35s/it]\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "data_extractor = SimpleLLMPathExtractor(llm=llm)\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(documents,\n",
    "                                          embed_model=embed_model,\n",
    "                                          kg_extractors=[data_extractor],\n",
    "                                          property_graph_store=graph_store,\n",
    "                                          show_progress=True,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import LLMSynonymRetriever, VectorContextRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_retriever = LLMSynonymRetriever(index.property_graph_store,\n",
    "                                  llm=llm,\n",
    "                                  include_text=False,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = VectorContextRetriever(index.property_graph_store,\n",
    "                                          embed_model=embed_model,\n",
    "                                          include_text=False,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(sub_retrievers=[synonym_retriever,\n",
    "                                               vector_retriever],\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = retriever.retrieve(\"Who is paul graham?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul graham -> Is -> Entrepreneur and writer\n",
      "Options -> Worth $2 million a month -> Paul graham\n",
      "Graham -> Founded in -> Viaweb\n",
      "Philz -> Is -> Coffee shop\n",
      "Philz -> Is coffee shop -> Founded in\n",
      "Robert -> Trevor -> Started investment firm\n"
     ]
    }
   ],
   "source": [
    "for triplet in context:\n",
    "    print(triplet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(include_text=True)\n",
    "\n",
    "response = query_engine.query(\"Who is paul grams?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided text, it appears that Paul Graham is an American entrepreneur, writer, and programmer. He is mentioned multiple times throughout the essay as being involved in various ventures, including:\n",
       "\n",
       "* Co-founding Viaweb with Robert Morris\n",
       "* Founding Interleaf, a software company that later became a part of Y Combinator's portfolio\n",
       "* Leaving Interleaf to start his own startup\n",
       "* Being a Lisp hacker and contributing to the development of Emacs\n",
       "\n",
       "There is also a mention of him being an entrepreneur and writer, which suggests that he has had a successful career in these fields. Additionally, there are references to him writing essays on topics such as painting, still life, and technology, indicating that he may have been involved in various creative pursuits throughout his life."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"{response.response}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Paul graham -> Is -> Entrepreneur and writer\n",
      "Options -> Worth $2 million a month -> Paul graham\n",
      "Graham -> Founded in -> Viaweb\n",
      "\n",
      "It was a huge relief when Yahoo bought us. In principle our Viaweb stock was valuable. It was a share in a business that was profitable and growing rapidly. But it didn't feel very valuable to me; I had no idea how to value a business, but I was all too keenly aware of the near-death experiences we seemed to have every few months. Nor had I changed my grad student lifestyle significantly since we started. So when Yahoo bought us it felt like going from rags to riches. Since we were going to California, I bought a car, a yellow 1998 VW GTI. I remember thinking that its leather seats alone were by far the most luxurious thing I owned.\n",
      "\n",
      "The next year, from the summer of 1998 to the summer of 1999, must have been the least productive of my life. I didn't realize it at the time, but I was worn out from the effort and stress of running Viaweb. For a while after I got to California I tried to continue my usual m.o. of programming till 3 in the morning, but fatigue combined with Yahoo's prematurely aged culture and grim cube farm in Santa Clara gradually dragged me down. After a few months it felt disconcertingly like working at Interleaf.\n",
      "\n",
      "Yahoo had given us a lot of options when they bought us. At the time I thought Yahoo was so overvalued that they'd never be worth anything, but to my astonishment the stock went up 5x in the next year. I hung on till the first chunk of options vested, then in the summer of 1999 I left. It had been so long since I'd painted anything that I'd half forgotten why I was doing this. My brain had been entirely full of software and men's shirts for 4 years. But I had done this to get rich so I could paint, I reminded myself, and now I was rich, so I should go paint.\n",
      "\n",
      "When I said I was leaving, my boss at Yahoo had a long conversation with me about my plans. I told him all about the kinds of pictures I wanted to paint. At the time I was touched that he took such an interest in me. Now I realize it was because he thought I was lying. My options at that point were worth about $2 million a month. If I was leaving that kind of money on the table, it could only be to go and start some new startup, and if I did, I might take people with me. This was the height of the Internet Bubble, and Yahoo was ground zero of it. My boss was at that moment a billionaire. Leaving then to start a new startup must have seemed to him an insanely, and yet also plausibly, ambitious plan.\n",
      "\n",
      "But I really was quitting to paint, and I started immediately. There was no time to lose. I'd already burned 4 years getting rich. Now when I talk to founders who are leaving after selling their companies, my advice is always the same: take a vacation. That's what I should have done, just gone off somewhere and done nothing for a month or two, but the idea never occurred to me.\n",
      "\n",
      "So I tried to paint, but I just didn't seem to have any energy or ambition. Part of the problem was that I didn't know many people in California. I'd compounded this problem by buying a house up in the Santa Cruz Mountains, with a beautiful view but miles from anywhere. I stuck it out for a few more months, then in desperation I went back to New York, where unless you understand about rent control you'll be surprised to hear I still had my apartment, sealed up like a tomb of my old life. Idelle was in New York at least, and there were other people trying to paint there, even though I didn't know any of them.\n",
      "\n",
      "When I got back to New York I resumed my old life, except now I was rich. It was as weird as it sounds. I resumed all my old patterns, except now there were doors where there hadn't been. Now when I was tired of walking, all I had to do was raise my hand, and (unless it was raining) a taxi would stop to pick me up. Now when I walked past charming little restaurants I could go in and order lunch. It was exciting for a while. Painting started to go better. I experimented with a new kind of still life where I'd paint one painting in the old way, then photograph it and print it, blown up, on canvas, and then use that as the underpainting for a second still life, painted from the same objects (which hopefully hadn't rotted yet).\n",
      "\n",
      "Meanwhile I looked for an apartment to buy.\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
